"""
æ•°æ®åŠ è½½å™¨ - CARE å®Œæ•´æ•°æ®æ ¼å¼é€‚é…ï¼ˆç»ˆæç‰ˆï¼‰

åŸºäºå®Œæ•´ eval.zip çš„æ·±åº¦åˆ†æï¼Œæ”¯æŒæ‰€æœ‰5ä¸ªæ•°æ®é›†çš„3ç§åŒ¹é…æ¨¡å¼ï¼š
1. ID åŒ¹é… (NQ)
2. Query åŒ¹é… (TriviaQA)
3. Question åŒ¹é… (WebQA, TruthfulQA, FactKG)

å…³é”®ä¿®æ­£ï¼š
- answer å­—æ®µï¼ˆä¸æ˜¯ answersï¼‰
- topk å­—æ®µï¼ˆä¸æ˜¯ ctxsï¼‰
- question_aware çš„ç‰¹æ®Šæ–‡æœ¬æ ¼å¼
- è‡ªåŠ¨æ£€æµ‹å¹¶é€‚é…3ç§åŒ¹é…æ¨¡å¼
"""

import json
import re
from pathlib import Path
from typing import List, Dict
from dataclasses import dataclass


@dataclass
class Sample:
    """ç»Ÿä¸€æ ·æœ¬æ ¼å¼"""
    id: str
    question: str
    answers: List[str]
    top1_context: str
    dataset: str


class CAREDataLoader:
    """CARE æ•°æ®æ ¼å¼åŠ è½½å™¨ï¼ˆç»ˆæç‰ˆ - æ”¯æŒæ‰€æœ‰3ç§åŒ¹é…æ¨¡å¼ï¼‰"""
    
    def __init__(self, data_root: str = "data_care/eval", verbose: bool = False):
        self.data_root = Path(data_root)
        self.verbose = verbose
        
        if not self.data_root.exists():
            raise FileNotFoundError(f"Data root not found: {data_root}")
    
    def load_dataset(self, dataset_name: str) -> List[Sample]:
        """
        åŠ è½½æ•°æ®é›†
        
        è‡ªåŠ¨æ£€æµ‹åŒ¹é…æ¨¡å¼ï¼š
        - å¦‚æœæ£€ç´¢æ–‡ä»¶æœ‰ id â†’ ä½¿ç”¨ ID åŒ¹é…ï¼ˆNQï¼‰
        - å¦‚æœæ£€ç´¢æ–‡ä»¶æœ‰ query â†’ ä½¿ç”¨ Query åŒ¹é…ï¼ˆTriviaQAï¼‰
        - å¦‚æœæ£€ç´¢æ–‡ä»¶æœ‰ question â†’ ä½¿ç”¨ Question åŒ¹é…ï¼ˆWebQA, TruthfulQA, FactKGï¼‰
        
        Args:
            dataset_name: nq, trivia, webqa, truthfulqa, factkg
        
        Returns:
            Sample å¯¹è±¡åˆ—è¡¨
        """
        # æ˜ å°„æ•°æ®é›†åç§°
        dataset_map = {
            'nq': 'nq',
            'trivia': 'triviaqa',
            'triviaqa': 'triviaqa',
            'webqa': 'webqa',
            'truthfulqa': 'truthfulqa',
            'factkg': 'factkg'
        }
        
        folder = dataset_map.get(dataset_name, dataset_name)
        dataset_dir = self.data_root / folder
        
        # æ–‡ä»¶è·¯å¾„
        question_file = dataset_dir / "test.jsonl"
        retrieval_file = dataset_dir / "retrieval" / "colbertv2" / "test_question_aware.jsonl"
        
        if self.verbose:
            print(f"\nğŸ“‚ Loading {dataset_name}:")
            print(f"  Question: {question_file}")
            print(f"  Retrieval: {retrieval_file}")
        
        # æ£€æŸ¥æ–‡ä»¶
        if not question_file.exists():
            raise FileNotFoundError(f"Question file not found: {question_file}")
        if not retrieval_file.exists():
            raise FileNotFoundError(f"Retrieval file not found: {retrieval_file}")
        
        # åŠ è½½æ•°æ®
        questions = self._load_jsonl(question_file)
        retrievals = self._load_jsonl(retrieval_file)
        
        if self.verbose:
            print(f"  Loaded: {len(questions)} questions, {len(retrievals)} retrievals")
        
        # æ£€æµ‹åŒ¹é…æ¨¡å¼
        match_mode = self._detect_match_mode(retrievals)
        
        if self.verbose:
            print(f"  Match mode: {match_mode}")
        
        # æ ¹æ®åŒ¹é…æ¨¡å¼åˆå¹¶æ•°æ®
        if match_mode == "ID":
            samples = self._merge_by_id(questions, retrievals, dataset_name)
        elif match_mode == "QUERY":
            samples = self._merge_by_query(questions, retrievals, dataset_name)
        elif match_mode == "QUESTION":
            samples = self._merge_by_question(questions, retrievals, dataset_name)
        else:
            raise ValueError(f"Unknown match mode: {match_mode}")
        
        print(f"âœ… Loaded {len(samples)} valid samples from {dataset_name}")
        return samples
    
    def _detect_match_mode(self, retrievals: List[Dict]) -> str:
        """
        è‡ªåŠ¨æ£€æµ‹åŒ¹é…æ¨¡å¼
        
        æ£€æµ‹é€»è¾‘ï¼š
        1. æ£€æŸ¥ç¬¬ä¸€æ¡è®°å½•æ˜¯å¦æœ‰ 'id' â†’ ID åŒ¹é…ï¼ˆNQï¼‰
        2. æ£€æŸ¥ç¬¬ä¸€æ¡è®°å½•æ˜¯å¦æœ‰ 'query' â†’ Query åŒ¹é…ï¼ˆTriviaQAï¼‰
        3. æ£€æŸ¥ç¬¬ä¸€æ¡è®°å½•æ˜¯å¦æœ‰ 'question' â†’ Question åŒ¹é…ï¼ˆWebQAç­‰ï¼‰
        
        Args:
            retrievals: æ£€ç´¢ç»“æœåˆ—è¡¨
        
        Returns:
            "ID", "QUERY", or "QUESTION"
        """
        if not retrievals:
            raise ValueError("Empty retrievals list")
        
        first = retrievals[0]
        
        if 'id' in first:
            return "ID"
        elif 'query' in first:
            return "QUERY"
        elif 'question' in first:
            return "QUESTION"
        else:
            raise ValueError(
                f"Cannot detect match mode. Available keys: {list(first.keys())}"
            )
    
    def _merge_by_id(
        self,
        questions: List[Dict],
        retrievals: List[Dict],
        dataset_name: str
    ) -> List[Sample]:
        """
        é€šè¿‡ ID åŒ¹é…åˆå¹¶æ•°æ®ï¼ˆNQ æ¨¡å¼ï¼‰
        
        ç‰¹ç‚¹ï¼š
        - æ£€ç´¢æ–‡ä»¶æœ‰ id å­—æ®µ
        - ä½¿ç”¨ zip éå†ï¼ŒO(n) æ—¶é—´å¤æ‚åº¦
        - è¦æ±‚æ–‡ä»¶é¡ºåºä¸€è‡´
        
        Args:
            questions: é—®é¢˜åˆ—è¡¨
            retrievals: æ£€ç´¢åˆ—è¡¨
            dataset_name: æ•°æ®é›†åç§°
        
        Returns:
            Sample åˆ—è¡¨
        """
        # éªŒè¯æ•°é‡
        if len(questions) != len(retrievals):
            print(f"  âš ï¸  Warning: question count ({len(questions)}) != retrieval count ({len(retrievals)})")
        
        samples = []
        skipped = 0
        
        for idx, (q, r) in enumerate(zip(questions, retrievals)):
            # éªŒè¯ ID åŒ¹é…ï¼ˆè½¬ä¸ºå­—ç¬¦ä¸²æ¯”è¾ƒï¼Œå› ä¸º NQ æ˜¯ intï¼Œå¯èƒ½æœ‰ç±»å‹å·®å¼‚ï¼‰
            q_id = str(q.get('id', ''))
            r_id = str(r.get('id', ''))
            
            if q_id != r_id:
                if self.verbose and skipped < 3:
                    print(f"  âš ï¸  Sample {idx}: ID mismatch (Q={q_id}, R={r_id})")
                skipped += 1
                continue
            
            # æå–å¹¶åˆ›å»ºæ ·æœ¬
            sample = self._create_sample(q, r, dataset_name, idx)
            if sample:
                samples.append(sample)
        
        if skipped > 0:
            print(f"  âš ï¸  Skipped {skipped} samples due to ID mismatch")
        
        return samples
    
    def _merge_by_query(
        self,
        questions: List[Dict],
        retrievals: List[Dict],
        dataset_name: str
    ) -> List[Sample]:
        """
        é€šè¿‡ Query åŒ¹é…åˆå¹¶æ•°æ®ï¼ˆTriviaQA æ¨¡å¼ï¼‰
        
        ç‰¹ç‚¹ï¼š
        - æ£€ç´¢æ–‡ä»¶æœ‰ query å­—æ®µï¼ˆæ—  idï¼‰
        - ä½¿ç”¨å­—å…¸åŒ¹é…ï¼ŒO(n) ç©ºé—´å’Œæ—¶é—´
        - ä¸ä¾èµ–æ–‡ä»¶é¡ºåº
        
        åŒ¹é…å…³ç³»: q['question'] == r['query']
        
        Args:
            questions: é—®é¢˜åˆ—è¡¨
            retrievals: æ£€ç´¢åˆ—è¡¨
            dataset_name: æ•°æ®é›†åç§°
        
        Returns:
            Sample åˆ—è¡¨
        """
        if self.verbose:
            print(f"  Using query-based matching (r['query'] == q['question'])")
        
        # åˆ›å»ºæ£€ç´¢å­—å…¸ï¼šquery -> retrieval
        retrieval_dict = {}
        for r in retrievals:
            query_text = r.get('query', '')
            if query_text:
                retrieval_dict[query_text] = r
        
        if self.verbose:
            print(f"  Built retrieval dict: {len(retrieval_dict)} entries")
        
        samples = []
        skipped = 0
        
        for idx, q in enumerate(questions):
            question_text = q.get('question', '')
            
            # é€šè¿‡ question æŸ¥æ‰¾å¯¹åº”çš„ query
            r = retrieval_dict.get(question_text)
            
            if r is None:
                if self.verbose and skipped < 3:
                    print(f"  âš ï¸  Sample {idx}: No retrieval found for: {question_text[:50]}...")
                skipped += 1
                continue
            
            # æå–å¹¶åˆ›å»ºæ ·æœ¬
            sample = self._create_sample(q, r, dataset_name, idx)
            if sample:
                samples.append(sample)
        
        if skipped > 0:
            print(f"  âš ï¸  Skipped {skipped} samples (no matching retrieval)")
        
        return samples
    
    def _merge_by_question(
        self,
        questions: List[Dict],
        retrievals: List[Dict],
        dataset_name: str
    ) -> List[Sample]:
        """
        é€šè¿‡ Question åŒ¹é…åˆå¹¶æ•°æ®ï¼ˆWebQA, TruthfulQA, FactKG æ¨¡å¼ï¼‰
        
        ç‰¹ç‚¹ï¼š
        - æ£€ç´¢æ–‡ä»¶æœ‰ question å­—æ®µï¼ˆæ—  idï¼‰
        - ä½¿ç”¨å­—å…¸åŒ¹é…ï¼ŒO(n) ç©ºé—´å’Œæ—¶é—´
        - ä¸ä¾èµ–æ–‡ä»¶é¡ºåº
        
        åŒ¹é…å…³ç³»: q['question'] == r['question']
        
        Args:
            questions: é—®é¢˜åˆ—è¡¨
            retrievals: æ£€ç´¢åˆ—è¡¨
            dataset_name: æ•°æ®é›†åç§°
        
        Returns:
            Sample åˆ—è¡¨
        """
        if self.verbose:
            print(f"  Using question-based matching (r['question'] == q['question'])")
        
        # åˆ›å»ºæ£€ç´¢å­—å…¸ï¼šquestion -> retrieval
        retrieval_dict = {}
        for r in retrievals:
            q_text = r.get('question', '')
            if q_text:
                retrieval_dict[q_text] = r
        
        if self.verbose:
            print(f"  Built retrieval dict: {len(retrieval_dict)} entries")
        
        samples = []
        skipped = 0
        
        for idx, q in enumerate(questions):
            question_text = q.get('question', '')
            
            # æŸ¥æ‰¾å¯¹åº”çš„æ£€ç´¢ç»“æœ
            r = retrieval_dict.get(question_text)
            
            if r is None:
                if self.verbose and skipped < 3:
                    print(f"  âš ï¸  Sample {idx}: No retrieval found for: {question_text[:50]}...")
                skipped += 1
                continue
            
            # æå–å¹¶åˆ›å»ºæ ·æœ¬
            sample = self._create_sample(q, r, dataset_name, idx)
            if sample:
                samples.append(sample)
        
        if skipped > 0:
            print(f"  âš ï¸  Skipped {skipped} samples (no matching retrieval)")
        
        return samples
    
    def _create_sample(
        self,
        question: Dict,
        retrieval: Dict,
        dataset_name: str,
        idx: int
    ) -> Sample:
        """
        åˆ›å»ºç»Ÿä¸€çš„ Sample å¯¹è±¡
        
        Args:
            question: é—®é¢˜å­—å…¸
            retrieval: æ£€ç´¢å­—å…¸
            dataset_name: æ•°æ®é›†åç§°
            idx: æ ·æœ¬ç´¢å¼•
        
        Returns:
            Sample å¯¹è±¡
        """
        # æå– IDï¼ˆä¼˜å…ˆä½¿ç”¨é—®é¢˜æ–‡ä»¶çš„ idï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç´¢å¼•ï¼‰
        sample_id = str(question.get('id', str(idx)))
        
        # æå–é—®é¢˜æ–‡æœ¬
        question_text = question.get('question', question.get('claim', ''))
        
        # æå–ç­”æ¡ˆï¼ˆå…³é”®ï¼šå­—æ®µåæ˜¯ answer ä¸æ˜¯ answersï¼‰
        answers = question.get('answer', question.get('answers', []))
        if not isinstance(answers, list):
            answers = [str(answers)]
        
        # æå– Top-1 context
        top1_ctx = self._extract_top1_context(retrieval, idx)
        
        return Sample(
            id=sample_id,
            question=question_text,
            answers=answers,
            top1_context=top1_ctx,
            dataset=dataset_name
        )
    
    def _extract_top1_context(self, retrieval: Dict, idx: int) -> str:
        """
        æå– Top-1 context
        
        Args:
            retrieval: æ£€ç´¢ç»“æœå­—å…¸
            idx: æ ·æœ¬ç´¢å¼•ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        
        Returns:
            æå–çš„æ–‡æ¡£å†…å®¹
        """
        top1_ctx = ""
        
        if retrieval.get('topk') and len(retrieval['topk']) > 0:
            raw_text = retrieval['topk'][0].get('text', '')
            
            # è§£æ question_aware çš„ç‰¹æ®Šæ ¼å¼
            top1_ctx = self._extract_document_text(raw_text)
            
            if self.verbose and idx == 0:
                print(f"\n  ğŸ” Sample 0 - Top-1 Context:")
                print(f"     Total contexts available: {len(retrieval['topk'])}")
                print(f"     Using: topk[0] (Top-1 only)")
                print(f"     Raw text preview: {raw_text[:200]}...")
                print(f"     Extracted context length: {len(top1_ctx)} chars")
                print(f"     Extracted context preview: {top1_ctx[:150]}...")
        
        return top1_ctx
    
    @staticmethod
    def _extract_document_text(raw_text: str) -> str:
        """
        ä» question_aware æ ¼å¼ä¸­æå– Document éƒ¨åˆ†
        
        æ ¼å¼ç¤ºä¾‹ï¼š
        "Question: when was the last time anyone was on the moon
         Document: Space technology | ... December 1972 ..."
        
        éœ€è¦æå– "Document:" ä¹‹åçš„éƒ¨åˆ†
        
        Args:
            raw_text: åŸå§‹æ–‡æœ¬
        
        Returns:
            æå–çš„æ–‡æ¡£å†…å®¹
        """
        # æ–¹æ³• 1: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– Document: ä¹‹åçš„å†…å®¹
        match = re.search(r'Document:\s*(.*)', raw_text, re.DOTALL)
        if match:
            return match.group(1).strip()
        
        # æ–¹æ³• 2: å¦‚æœæ²¡æœ‰ Document: æ ‡è®°ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰ Question: æ ‡è®°
        if 'Question:' in raw_text:
            # åˆ†å‰²å¹¶å–ç¬¬äºŒéƒ¨åˆ†
            parts = raw_text.split('Document:', 1)
            if len(parts) > 1:
                return parts[1].strip()
            # å¦‚æœåªæœ‰ Questionï¼Œå»æ‰å®ƒ
            parts = raw_text.split('\n', 1)
            if len(parts) > 1:
                return parts[1].strip()
        
        # æ–¹æ³• 3: å¦‚æœéƒ½æ²¡æœ‰ï¼Œç›´æ¥è¿”å›åŸæ–‡
        return raw_text.strip()
    
    @staticmethod
    def _load_jsonl(file_path: Path) -> List[Dict]:
        """è¯»å– JSONL æ–‡ä»¶"""
        data = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line:
                    continue
                try:
                    data.append(json.loads(line))
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  Line {line_num}: {e}")
        return data